{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Multi-Agent Debate Demo\n\nThis notebook demonstrates the RoundtableAI multi-agent debate system:\n- **Natural language query routing** - The orchestrator classifies queries and routes to appropriate agent(s)\n- **Risk tolerance inference** - Automatically infers investor risk profile from query language\n- **Multi-agent debates** - Running debates with consensus tracking\n- **Single agent queries** - Simple factual queries handled by single specialists\n\nThe system uses three specialist agents:\n1. **Fundamental Agent**: Analyzes financial statements\n2. **Sentiment Agent**: Analyzes news sentiment  \n3. **Valuation Agent**: Analyzes risk-return metrics"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add project root to path\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import debate components\n",
    "from agents import (\n",
    "    DebateOrchestrator,\n",
    "    create_debate_orchestrator,\n",
    "    DebateManager,\n",
    "    DebateState,\n",
    "    Recommendation,\n",
    "    get_llm\n",
    ")\n",
    "\n",
    "# Import evaluation components\n",
    "from evaluation import DebateEvaluator\n",
    "\n",
    "# Import configuration\n",
    "from utils.config import get_debate_config\n",
    "\n",
    "print(\"Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. Initialize the LLM (Google Gemini)\n\nConnect to Gemini 2.0 Flash via Google AI API.\n\n**Prerequisites:**\n1. Get API key from: https://aistudio.google.com/apikey\n2. Set `GOOGLE_API_KEY` in `.env` file"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Connect to Gemini LLM (singleton - reused across agents)\nllm = get_llm(\n    model_name=\"gemini-2.0-flash\",\n    temperature=0.3\n)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create the Debate Orchestrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View debate configuration\n",
    "debate_config = get_debate_config()\n",
    "print(\"Debate Configuration:\")\n",
    "for key, value in debate_config.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback to track debate progress\n",
    "def on_message(message):\n",
    "    \"\"\"Called when an agent posts a message.\"\"\"\n",
    "    agent = message.agent_type\n",
    "    rec = message.recommendation.value\n",
    "    conf = message.confidence\n",
    "    round_num = message.round_number\n",
    "    print(f\"[Round {round_num}] {agent.upper()}: {rec} ({conf:.0%} confidence)\")\n",
    "\n",
    "def on_round_complete(round_result):\n",
    "    \"\"\"Called when a debate round completes.\"\"\"\n",
    "    round_num = round_result.round_number\n",
    "    consensus = round_result.consensus_percentage\n",
    "    leading = round_result.leading_recommendation.value\n",
    "    print(f\"\\n--- Round {round_num} Complete ---\")\n",
    "    print(f\"Consensus: {consensus:.0%}, Leading: {leading}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the orchestrator\n",
    "orchestrator = create_debate_orchestrator(\n",
    "    llm=llm,\n",
    "    max_rounds=5,\n",
    "    consensus_threshold=0.75,\n",
    "    on_message_callback=on_message\n",
    ")\n",
    "\n",
    "print(\"Orchestrator created successfully!\")\n",
    "print(f\"Agents: {list(orchestrator.agents.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. Route Natural Language Queries\n\nThe orchestrator's `route_query()` method:\n1. **Classifies the query** - Determines if multi-agent debate or single agent is needed\n2. **Extracts company/ticker** - Identifies which stock is being asked about\n3. **Infers risk tolerance** - Detects conservative/moderate/aggressive from language\n4. **Routes appropriately** - Sends to debate or single agent"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Example 1: Investment recommendation query (triggers multi-agent debate)\n# Risk tolerance will be inferred as \"moderate\" (default)\n\nuser_query = \"Should I invest in Maybank? I'm looking for a balanced investment.\"\n\nprint(f\"User Query: {user_query}\")\nprint(f\"\\n{'='*60}\")\nprint(\"Processing query...\")\nprint(f\"{'='*60}\\n\")\n\n# Route the query - this will:\n# 1. Classify the query (needs debate)\n# 2. Extract company (Maybank)\n# 3. Infer risk tolerance (moderate - \"balanced\")\n# 4. Run multi-agent debate\nresult = orchestrator.route_query(user_query)\n\nprint(f\"\\nRoute Type: {result['route_type']}\")\nprint(f\"Risk Tolerance: {result.get('risk_tolerance', 'N/A')}\")\nprint(f\"Classification: {result.get('classification', {})}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Display result based on route type\nif result['route_type'] == 'debate':\n    print(\"\\n\" + \"=\"*60)\n    print(\"MULTI-AGENT DEBATE RESULT\")\n    print(\"=\"*60)\n    \n    print(f\"\\nRecommendation: {result['recommendation']}\")\n    print(f\"Confidence: {result['confidence']:.0%}\")\n    print(f\"Consensus Level: {result['consensus']:.0%}\")\n    print(f\"Risk Tolerance Applied: {result['risk_tolerance'].upper()}\")\n    \n    # Access full result for more details\n    final_rec = result['full_result']\n    \n    print(\"\\nKey Points:\")\n    for point in final_rec.key_points:\n        print(f\"  - {point}\")\n\n    print(\"\\nKey Risks:\")\n    for risk in final_rec.risks:\n        print(f\"  - {risk}\")\n        \nelif result['route_type'] == 'single_agent':\n    print(\"\\n\" + \"=\"*60)\n    print(\"SINGLE AGENT RESPONSE\")\n    print(\"=\"*60)\n    print(f\"\\nAgent Used: {result['agent_used']}\")\n    print(f\"Response:\\n{result['response'][:1000]}...\")\n    \nelse:\n    print(f\"\\nError: {result['response']}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# View agent breakdown (only if debate was run)\nif result['route_type'] == 'debate':\n    final_rec = result['full_result']\n    print(\"Agent Breakdown:\")\n    print(\"-\"*40)\n    for agent_type, vote in final_rec.agent_breakdown.items():\n        print(f\"\\n{agent_type.upper()}:\")\n        print(f\"  Recommendation: {vote.recommendation.value}\")\n        print(f\"  Confidence: {vote.confidence:.0%}\")\n        print(f\"  Reasoning: {vote.reasoning[:200]}...\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5. Risk Tolerance Inference Examples\n\nThe orchestrator infers risk tolerance from natural language cues:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Test risk tolerance inference with different query styles\n\ntest_queries = [\n    # Conservative queries\n    \"I'm nearing retirement and want a safe dividend stock. Is Maybank suitable for capital preservation?\",\n    \n    # Moderate queries  \n    \"Looking for a balanced investment in CIMB with reasonable growth potential.\",\n    \n    # Aggressive queries\n    \"I want maximum growth and don't mind volatility. Should I buy Public Bank for high returns?\"\n]\n\nprint(\"Risk Tolerance Inference Demo\")\nprint(\"=\"*60)\n\nfor query in test_queries:\n    print(f\"\\nQuery: {query[:80]}...\")\n    \n    # Just classify without running full debate\n    classification = orchestrator.classify_query(query)\n    \n    print(f\"  → Risk Tolerance: {classification['risk_tolerance'].upper()}\")\n    print(f\"  → Company: {classification.get('company', 'N/A')}\")\n    print(f\"  → Needs Debate: {classification['needs_debate']}\")\n    print(f\"  → Reasoning: {classification['reasoning'][:100]}...\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 6. Single Agent Queries\n\nSome queries only need a single specialist agent:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Example: Single agent query (sentiment-specific)\nsingle_query = \"What is the recent news sentiment for CIMB?\"\n\nprint(f\"Query: {single_query}\")\nprint(\"-\"*40)\n\n# Classify first to show routing decision\nclassification = orchestrator.classify_query(single_query)\nprint(f\"Classification:\")\nprint(f\"  Needs Debate: {classification['needs_debate']}\")\nprint(f\"  Agent: {classification['agent_type']}\")\nprint(f\"  Company: {classification.get('company')}\")\n\n# Route the query\nresult = orchestrator.route_query(single_query)\n\nprint(f\"\\nRoute Type: {result['route_type']}\")\nprint(f\"Agent Used: {result['agent_used']}\")\nprint(f\"\\nResponse Preview:\")\nprint(result['response'][:800] + \"...\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Example: Valuation-specific query\nvaluation_query = \"What is the volatility and Sharpe ratio for Maybank?\"\n\nprint(f\"Query: {valuation_query}\")\nprint(\"-\"*40)\n\nresult = orchestrator.route_query(valuation_query)\n\nprint(f\"Route Type: {result['route_type']}\")\nprint(f\"Agent Used: {result['agent_used']}\")\nprint(f\"\\nResponse Preview:\")\nprint(result['response'][:800] + \"...\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 7. Conservative Investor Analysis\n\nRun a full debate with explicit conservative risk tolerance:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Conservative investor query - explicit risk tolerance in language\nconservative_query = \"I'm a retiree looking for a safe, stable dividend stock. Should I invest in Maybank for capital preservation?\"\n\nprint(f\"Query: {conservative_query}\")\nprint(f\"\\n{'='*60}\")\nprint(\"Running analysis for CONSERVATIVE investor...\")\nprint(f\"{'='*60}\\n\")\n\n# Route query - will infer conservative risk tolerance\nresult = orchestrator.route_query(conservative_query)\n\n# Debug: Show classification details\nprint(\"Classification Details:\")\nclassification = result.get('classification', {})\nprint(f\"  Needs Debate: {classification.get('needs_debate')}\")\nprint(f\"  Agent Type: {classification.get('agent_type')}\")\nprint(f\"  Company: {classification.get('company')}\")\nprint(f\"  Reasoning: {classification.get('reasoning')}\")\n\nprint(f\"\\nRoute Type: {result['route_type']}\")\nprint(f\"Inferred Risk Tolerance: {result['risk_tolerance'].upper()}\")\nprint(f\"Recommendation: {result.get('recommendation', 'N/A')}\")\n\nif result['route_type'] == 'debate':\n    print(f\"Confidence: {result['confidence']:.0%}\")\n    print(f\"Consensus: {result['consensus']:.0%}\")\nelif result['route_type'] == 'single_agent':\n    print(f\"Agent Used: {result['agent_used']}\")\n    print(f\"\\nResponse Preview:\\n{result['response'][:500]}...\")\nelif result['route_type'] == 'error':\n    print(f\"Error: {result['response']}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Aggressive investor query\naggressive_query = \"I want maximum growth and I'm willing to take high risks. Should I buy CIMB for aggressive returns?\"\n\nprint(f\"Query: {aggressive_query}\")\nprint(f\"\\n{'='*60}\")\nprint(\"Running analysis for AGGRESSIVE investor...\")\nprint(f\"{'='*60}\\n\")\n\n# Route query - will infer aggressive risk tolerance\nresult = orchestrator.route_query(aggressive_query)\n\nprint(f\"\\nInferred Risk Tolerance: {result['risk_tolerance'].upper()}\")\nprint(f\"Recommendation: {result.get('recommendation', 'N/A')}\")\nif result['route_type'] == 'debate':\n    print(f\"Confidence: {result['confidence']:.0%}\")\n    print(f\"Consensus: {result['consensus']:.0%}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 8. View Debate Transcript"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Get debate transcript from the most recent debate\ntranscript = orchestrator.get_debate_transcript()\nprint(transcript)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Evaluate debate quality\nevaluator = DebateEvaluator()\n\n# Get debate data from orchestrator\ndebate_data = orchestrator.export_debate()\n\nif debate_data:\n    # Get the final recommendation from the last result\n    final_rec_value = result.get('recommendation', 'HOLD')\n    \n    # Evaluate the debate\n    metrics = evaluator.evaluate_debate(\n        debate_state=debate_data,\n        final_recommendation=final_rec_value\n    )\n\n    print(\"Debate Quality Metrics:\")\n    print(\"-\"*40)\n    print(f\"Consensus Quality:     {metrics.consensus_quality:.1%}\")\n    print(f\"Reasoning Consistency: {metrics.reasoning_consistency:.1%}\")\n    print(f\"Convergence Rate:      {metrics.convergence_rate:.1%}\")\n    print(f\"Recommendation Conf.:  {metrics.recommendation_confidence:.1%}\")\n    print(f\"Rounds to Consensus:   {metrics.rounds_to_consensus}\")\n    print(f\"Total Messages:        {metrics.total_messages}\")\nelse:\n    print(\"No debate data available. Run a debate first.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Summary\n\nThis notebook demonstrated:\n- **Natural language query routing** via `orchestrator.route_query()`\n- **Automatic risk tolerance inference** from query language (conservative/moderate/aggressive)\n- **Query classification** - determining single agent vs multi-agent debate\n- **Multi-agent debates** with three specialist agents\n- **Single agent queries** for specific factual information\n- **Debate evaluation** with quality metrics\n\n### Key API Methods:\n```python\n# Main entry point - routes query automatically\nresult = orchestrator.route_query(\"Should I invest in Maybank?\")\n\n# Just classify without running (useful for testing)\nclassification = orchestrator.classify_query(\"Is CIMB a safe investment?\")\n\n# Direct debate (bypasses classification)\nrecommendation = orchestrator.run_debate(\"Maybank\", risk_tolerance=\"conservative\")\n```\n\n### Next Steps:\n1. Run `streamlit run app.py` to launch the interactive UI\n2. Try different query styles to see risk tolerance inference\n3. Compare recommendations for same stock with different risk profiles"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}