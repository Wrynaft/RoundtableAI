{
  "evaluation_date": "2026-01-07T22:03:55.968896",
  "models_tested": [
    "gemini-2.0-flash",
    "gemini-2.5-pro",
    "gemini-2.0-flash-lite"
  ],
  "total_test_cases": 162,
  "per_model_metrics": {
    "gemini-2.0-flash": {
      "agents": {
        "fundamental": {
          "accuracy": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "f1_score": 1.0,
          "exact_matches": 17,
          "total_cases": 17,
          "error_count": 1,
          "successful_cases": 17
        },
        "sentiment": {
          "accuracy": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "f1_score": 1.0,
          "exact_matches": 18,
          "total_cases": 18,
          "error_count": 0,
          "successful_cases": 18
        },
        "valuation": {
          "accuracy": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "f1_score": 1.0,
          "exact_matches": 18,
          "total_cases": 18,
          "error_count": 0,
          "successful_cases": 18
        }
      }
    },
    "gemini-2.5-pro": {
      "agents": {
        "fundamental": {
          "accuracy": 0.9444444444444444,
          "precision": 1.0,
          "recall": 0.9803921568627451,
          "f1_score": 0.99009900990099,
          "exact_matches": 17,
          "total_cases": 18,
          "error_count": 0,
          "successful_cases": 18
        },
        "sentiment": {
          "accuracy": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "f1_score": 1.0,
          "exact_matches": 16,
          "total_cases": 16,
          "error_count": 2,
          "successful_cases": 16
        },
        "valuation": {
          "accuracy": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "f1_score": 1.0,
          "exact_matches": 18,
          "total_cases": 18,
          "error_count": 0,
          "successful_cases": 18
        }
      }
    },
    "gemini-2.0-flash-lite": {
      "agents": {
        "fundamental": {
          "accuracy": 0.8823529411764706,
          "precision": 0.9791666666666666,
          "recall": 0.9791666666666666,
          "f1_score": 0.9791666666666666,
          "exact_matches": 15,
          "total_cases": 17,
          "error_count": 1,
          "successful_cases": 17
        },
        "sentiment": {
          "accuracy": 0.5555555555555556,
          "precision": 1.0,
          "recall": 0.84,
          "f1_score": 0.9130434782608696,
          "exact_matches": 10,
          "total_cases": 18,
          "error_count": 0,
          "successful_cases": 18
        },
        "valuation": {
          "accuracy": 1.0,
          "precision": 1.0,
          "recall": 1.0,
          "f1_score": 1.0,
          "exact_matches": 18,
          "total_cases": 18,
          "error_count": 0,
          "successful_cases": 18
        }
      }
    }
  }
}